import os
import torch
import glob
import rasterio
import numpy as np
import argparse  # å¯¼å…¥argparse
import sys  # ç”¨äºé€€å‡ºç¨‹åº
from torchvision import models
import torch.nn as nn
from colorama import init, Fore, Style

# åˆå§‹åŒ–coloramaï¼Œè‡ªåŠ¨é‡ç½®æ ·å¼
init(autoreset=True)
RED_BOLD = f"{Fore.RED}{Style.BRIGHT}"
RESET = Style.RESET_ALL


# --- æ–°å¢ï¼šå‘½ä»¤è¡Œå‚æ•°è§£æï¼ˆå®Œå…¨æ‰‹åŠ¨æ§åˆ¶ï¼‰---
def parse_args():
    # åˆ›å»ºå‚æ•°è§£æå™¨ï¼ˆå…³é—­åŸç”Ÿhelpï¼Œæ‰‹åŠ¨æ§åˆ¶ï¼‰
    parser = argparse.ArgumentParser(
        description='æå–TIFæ–‡ä»¶çš„CNNç‰¹å¾å¹¶ä¿å­˜ä¸ºPTæ–‡ä»¶',
        formatter_class=argparse.RawTextHelpFormatter,
        add_help=False  # å…³é—­åŸç”Ÿhelp
    )

    # å…³é”®ï¼šå»æ‰required=Trueï¼Œæ”¹ç”¨æ‰‹åŠ¨æ ¡éªŒ
    parser.add_argument(
        '-d', '--data_dir',
        type=str,
        help='å­˜æ”¾TIFæ–‡ä»¶çš„ç›®å½•ï¼ˆå¿…é€‰ï¼‰ï¼Œä¾‹å¦‚ï¼š\n./csv_tif \næˆ– /home/user/tif_files'
    )

    parser.add_argument(
        '-f', '--feature_dir',
        type=str,
        help='ä¿å­˜æå–ç‰¹å¾çš„ç›®å½•ï¼ˆå¿…é€‰ï¼‰ï¼Œä¾‹å¦‚ï¼š\n./extracted_features \næˆ– /home/user/features'
    )

    # æ‰‹åŠ¨æ·»åŠ helpå‚æ•°
    parser.add_argument(
        '-h', '--help',
        action='store_true',
        help='æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯å¹¶é€€å‡º'
    )

    # å…³é”®ï¼šä½¿ç”¨parse_known_args()é¿å…åŸç”Ÿå¼‚å¸¸
    args, unknown = parser.parse_known_args()

    # 1. å¤„ç†å¸®åŠ©è¯·æ±‚
    if args.help:
        print("=" * 80)
        print("ğŸ“– TIFç‰¹å¾æå–å·¥å…· - ä½¿ç”¨å¸®åŠ©")
        print("=" * 80)
        parser.print_help()
        sys.exit(0)

    # 2. æ‰‹åŠ¨æ ¡éªŒå¿…é€‰å‚æ•°
    missing_args = []
    if not args.data_dir:
        missing_args.append('-d/--data_dir')
    if not args.feature_dir:
        missing_args.append('-f/--feature_dir')

    if missing_args:
        print(f"\nâŒ å‚æ•°é”™è¯¯ï¼šç¼ºå°‘å¿…é€‰å‚æ•° â†’ {', '.join(missing_args)}")
        print("\nğŸ“– å®Œæ•´ä½¿ç”¨è¯´æ˜ï¼š")
        parser.print_help()
        sys.exit(1)

    # 3. æ ¡éªŒdata_diræ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.data_dir):
        print(f"\nâŒ é”™è¯¯ï¼šæŒ‡å®šçš„TIFç›®å½•ä¸å­˜åœ¨ â†’ {args.data_dir}")
        print("\nğŸ“– å®Œæ•´ä½¿ç”¨è¯´æ˜ï¼š")
        parser.print_help()
        sys.exit(1)

    # 4. æ ¡éªŒdata_dirä¸‹æ˜¯å¦æœ‰TIFæ–‡ä»¶
    tif_files = glob.glob(os.path.join(args.data_dir, "*.tif"))
    if len(tif_files) == 0:
        print(f"\nâŒ é”™è¯¯ï¼š{args.data_dir} ç›®å½•ä¸‹æœªæ‰¾åˆ°ä»»ä½•.tifæ–‡ä»¶")
        print("\nğŸ“– å®Œæ•´ä½¿ç”¨è¯´æ˜ï¼š")
        parser.print_help()
        sys.exit(1)

    return args


# --- ä¸»é€»è¾‘ ---
def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()

    # é…ç½®ï¼ˆä»å‘½ä»¤è¡Œå‚æ•°è¯»å–ï¼‰
    data_dir = args.data_dir
    feature_dir = args.feature_dir
    os.makedirs(feature_dir, exist_ok=True)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    print(f"ğŸ“Œ ä½¿ç”¨é…ç½®ï¼š")
    print(f"   TIFæ–‡ä»¶ç›®å½•: {data_dir}")
    print(f"   ç‰¹å¾ä¿å­˜ç›®å½•: {feature_dir}")
    print(f"   è®¡ç®—è®¾å¤‡: {device}")

    # 1. å®šä¹‰å’ŒåŠ è½½CNN Backbone
    base = models.resnet18(pretrained=True).to(device)
    # åªè¦ ResNet çš„å‰ 8 å±‚ï¼ˆå»æ‰å…¨è¿æ¥å’Œæ± åŒ–ï¼‰ï¼Œè¾“å‡º [512, H/32, W/32]
    cnn_backbone = nn.Sequential(*list(base.children())[:-2])
    # ä¿®æ”¹ç¬¬ä¸€å±‚å·ç§¯ä»¥åŒ¹é…20æ³¢æ®µè¾“å…¥
    cnn_backbone[0] = nn.Conv2d(20, 64, kernel_size=7, stride=1, padding=3, bias=False).to(device)
    cnn_backbone.eval()

    def process_tif(img_path):
        with rasterio.open(img_path) as src:
            img_data = src.read().astype(np.float32)
            # å½’ä¸€åŒ–é€»è¾‘ (ä¸ä¸»ç¨‹åºä¿æŒä¸€è‡´)
            for i in range(img_data.shape[0]):
                ch_min, ch_max = img_data[i].min(), img_data[i].max()
                denom = ch_max - ch_min
                if denom > 1e-6:
                    img_data[i] = (img_data[i] - ch_min) / denom
                else:
                    img_data[i] = 0.0
            return torch.from_numpy(img_data).unsqueeze(0).to(device)

    # 2. éå†å¹¶ä¿å­˜ç‰¹å¾
    tif_files = glob.glob(os.path.join(data_dir, "*.tif"))
    print(f"\nğŸš€ å¼€å§‹æå– {len(tif_files)} ä¸ªæ–‡ä»¶çš„ç‰¹å¾...")

    with torch.no_grad():
        for idx, t_path in enumerate(tif_files, 1):
            fname = os.path.basename(t_path).replace('.tif', '.pt')
            save_path = os.path.join(feature_dir, fname)

            # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶ï¼ˆå¯é€‰ä¼˜åŒ–ï¼‰
            if os.path.exists(save_path):
                print(f"[{idx}/{len(tif_files)}] å·²å­˜åœ¨ï¼Œè·³è¿‡: {fname}")
                continue

            img_tensor = process_tif(t_path)
            feat_map = cnn_backbone(img_tensor)  # å¾—åˆ°ç‰¹å¾å›¾

            # å­˜å…¥ç¡¬ç›˜ (è½¬åˆ° CPU èŠ‚çœæ˜¾å­˜)
            torch.save(feat_map.cpu(), save_path)
            print(f"[{idx}/{len(tif_files)}] å·²ä¿å­˜: {fname}")

    # ä¿®å¤ï¼šå»æ‰args.argsçš„ç¬”è¯¯ï¼Œæ”¹ä¸ºargs.feature_dir
    print(f"\n{RED_BOLD}ä¿å­˜æå–ç‰¹å¾çš„ç›®å½•ä¸ºï¼š{feature_dir}{RESET}")
    print("\nâœ… ç‰¹å¾æå–å®Œæˆï¼")


if __name__ == "__main__":
    main()